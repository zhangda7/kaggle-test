{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fd9f01ab38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pylab as P\n",
    "df = pd.read_csv('data/titanic/train.csv', header=0)\n",
    "df['Pclass'].hist()\n",
    "P.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 13)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'] = df['Sex'].map({'female':0, 'male':1}).astype(int)\n",
    "#df = df.dropna()\n",
    "train_data = df.values\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 12)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/titanic/train.csv', header=0)\n",
    "test_df = pd.read_csv('data/titanic/test.csv', header=0)\n",
    "full_df = train_df.append(test_df, ignore_index = True)\n",
    "print(full_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sex = pd.Series( np.where( full_df.Sex == 'male' , 1 , 0 ) , name = 'Sex' )\n",
    "#full_df.head()\n",
    "#embarked = pd.get_dummies(full_df.Embarked, prefix = 'Embarked')\n",
    "#embarked.head()\n",
    "#pClass = pd.get_dummies(full_df.Pclass, prefix = 'Pclass')\n",
    "#pClass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Student</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Braund,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4_quartile</td>\n",
       "      <td>C</td>\n",
       "      <td>Cumings,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Heikkinen,</td>\n",
       "      <td>Miss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4_quartile</td>\n",
       "      <td>C</td>\n",
       "      <td>Futrelle,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Allen,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Sex          Age  SibSp  Parch  \\\n",
       "0            1         0       3    male      Student      1      0   \n",
       "1            2         1       1  female        Adult      1      0   \n",
       "2            3         1       3  female  Young Adult      0      0   \n",
       "3            4         1       1  female  Young Adult      1      0   \n",
       "4            5         0       3    male  Young Adult      0      0   \n",
       "\n",
       "         Fare Cabin       Lname NamePrefix  \n",
       "0  1_quartile     N     Braund,        Mr.  \n",
       "1  4_quartile     C    Cumings,       Mrs.  \n",
       "2  1_quartile     N  Heikkinen,      Miss.  \n",
       "3  4_quartile     C   Futrelle,       Mrs.  \n",
       "4  2_quartile     N      Allen,        Mr.  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#below code copy from https://www.kaggle.com/jeffd23/scikit-learn-ml-from-start-to-finish\n",
    "#just to familier data transform\n",
    "def simplify_ages(df):\n",
    "    df.Age = df.Age.fillna(-0.5)\n",
    "    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n",
    "    group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n",
    "    categories = pd.cut(df.Age, bins, labels=group_names)\n",
    "    df.Age = categories\n",
    "    return df\n",
    "\n",
    "def simplify_cabins(df):\n",
    "    df.Cabin = df.Cabin.fillna('N')\n",
    "    df.Cabin = df.Cabin.apply(lambda x: x[0])\n",
    "    return df\n",
    "\n",
    "def simplify_fares(df):\n",
    "    df.Fare = df.Fare.fillna(-0.5)\n",
    "    bins = (-1, 0, 8, 15, 31, 1000)\n",
    "    group_names = ['Unknown', '1_quartile', '2_quartile', '3_quartile', '4_quartile']\n",
    "    categories = pd.cut(df.Fare, bins, labels=group_names)\n",
    "    df.Fare = categories\n",
    "    return df\n",
    "\n",
    "def format_name(df):\n",
    "    df['Lname'] = df.Name.apply(lambda x: x.split(' ')[0])\n",
    "    df['NamePrefix'] = df.Name.apply(lambda x: x.split(' ')[1])\n",
    "    return df    \n",
    "    \n",
    "def drop_features(df):\n",
    "    return df.drop(['Ticket', 'Name', 'Embarked'], axis=1)\n",
    "\n",
    "def transform_features(df):\n",
    "    df = simplify_ages(df)\n",
    "    df = simplify_cabins(df)\n",
    "    df = simplify_fares(df)\n",
    "    df = format_name(df)\n",
    "    df = drop_features(df)\n",
    "    return df\n",
    "\n",
    "data_train = transform_features(train_df)\n",
    "data_test = transform_features(test_df)\n",
    "data_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>329</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>267</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex  Age  SibSp  Parch  Fare  Cabin  Lname  \\\n",
       "0            1         0       3    1    4      1      0     0      7    100   \n",
       "1            2         1       1    0    0      1      0     3      2    182   \n",
       "2            3         1       3    0    7      0      0     0      7    329   \n",
       "3            4         1       1    0    7      1      0     3      2    267   \n",
       "4            5         0       3    1    7      0      0     1      7     15   \n",
       "\n",
       "   NamePrefix  \n",
       "0          19  \n",
       "1          20  \n",
       "2          16  \n",
       "3          20  \n",
       "4          19  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "def encode_features(df_train, df_test):\n",
    "    features = ['Fare', 'Cabin', 'Age', 'Sex', 'Lname', 'NamePrefix']\n",
    "    df_combined = pd.concat([df_train[features], df_test[features]])\n",
    "    \n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(df_combined[feature])\n",
    "        df_train[feature] = le.transform(df_train[feature])\n",
    "        df_test[feature] = le.transform(df_test[feature])\n",
    "    return df_train, df_test\n",
    "    \n",
    "data_train, data_test = encode_features(data_train, data_test)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 418)\n",
      "X Train:(712, 9)\n",
      "Y Train:(712,)\n",
      "X_train :  (9, 712)\n",
      "Y train :  (712, 1)\n",
      "X_test :  (9, 179)\n",
      "Y test :  (179, 1)\n",
      "X_train :  (9, 712)\n",
      "y_train:  (2, 712)\n",
      "X_test :  (9, 179)\n",
      "y_test:  (2, 179)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_all = data_train.drop(['Survived', 'PassengerId'], axis=1)\n",
    "y_all = data_train['Survived']\n",
    "\n",
    "X_test_all = data_test.drop(['PassengerId'], axis=1).T\n",
    "print(X_test_all.shape)\n",
    "num_test = 0.20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=num_test, random_state=23)\n",
    "print(\"X Train:\" + str(X_train.shape))\n",
    "print(\"Y Train:\" + str(y_train.shape))\n",
    "\n",
    "X_pd_train = X_train.T\n",
    "y_pd_train = y_train.values.reshape(y_train.shape[0], 1)\n",
    "#y_train = y_train.T\n",
    "\n",
    "X_pd_test = X_test.T\n",
    "y_pd_test = y_test.values.reshape(y_test.shape[0], 1)\n",
    "#y_test = y_test.T\n",
    "print(\"X_train : \", X_pd_train.shape)\n",
    "print(\"Y train : \", y_pd_train.shape)\n",
    "print(\"X_test : \", X_pd_test.shape)\n",
    "print(\"Y test : \", y_pd_test.shape)\n",
    "\n",
    "#yy = tf.one_hot(y_train, depth=2)\n",
    "y_train1 = np.eye(2)[y_train.values.reshape(y_train.shape[0])]\n",
    "\n",
    "y_train = y_train1.T\n",
    "\n",
    "y_test1 = np.eye(2)[y_test.values.reshape(y_test.shape[0])]\n",
    "\n",
    "y_test = y_test1.T\n",
    "print(\"X_train : \", X_pd_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"X_test : \", X_pd_test.shape)\n",
    "print(\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
    "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "    \n",
    "    Tips:\n",
    "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    X = tf.placeholder(tf.float32, shape = (n_x, None))\n",
    "    Y = tf.placeholder(tf.float32, shape = (n_y, None))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [25, 9]\n",
    "                        b1 : [25, 1]\n",
    "                        W2 : [12, 25]\n",
    "                        b2 : [12, 1]\n",
    "                        W3 : [1, 12]\n",
    "                        b3 : [1, 1]\n",
    "    W.shape(n(l), n_x)\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 6 lines of code)\n",
    "    W1 = tf.get_variable(\"W1\", [125,9], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [125,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [120, 125], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [120, 1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [100, 120], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [100, 1], initializer = tf.zeros_initializer())\n",
    "    W4 = tf.get_variable(\"W4\", [2, 100], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b4 = tf.get_variable(\"b4\", [2, 1], initializer = tf.zeros_initializer())\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3,\n",
    "                  \"W4\": W4,\n",
    "                  \"b4\": b4}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    W4 = parameters['W4']\n",
    "    b4 = parameters['b4']\n",
    "    \n",
    "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                                              # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                              # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                                              # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                              # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)                                              # Z2 = np.dot(W2, a1) + b2\n",
    "    A3 = tf.nn.relu(Z3)  \n",
    "    Z4 = tf.add(tf.matmul(W4, A3), b4)                                              # Z3 = np.dot(W3,Z2) + b3\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return Z4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(Z4, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z4)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def random_mini_batches(X_train, Y_train, minibatch_size, seed):\n",
    "    minibatches = []\n",
    "    length = X_train.shape[1]\n",
    "    batch_count = length / minibatch_size\n",
    "    #print(batch_count)\n",
    "    startRandom = random.randint(0, length)\n",
    "    for i in range(int(batch_count)):\n",
    "        start = startRandom + i * minibatch_size\n",
    "        end = start + minibatch_size\n",
    "        if(start >= length):\n",
    "            start -= length\n",
    "        if(end >= length):\n",
    "            end -= length\n",
    "        if(start > end):\n",
    "            minibatches.append( (X_train[:,start:length], y_train[:,start:length]) )\n",
    "            minibatches.append( (X_train[:,:end], y_train[:,:end]) )\n",
    "            continue\n",
    "        \n",
    "        minibatch = (X_train[:,start:end], y_train[:,start:end])\n",
    "       # print(minibatch[0].shape, start, end)\n",
    "        minibatches.append(minibatch)\n",
    "    return minibatches\n",
    "minibatches = random_mini_batches(X_train, y_train, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 1500, minibatch_size = 32, print_cost = True, restore_params = False):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
    "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
    "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
    "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z4 = forward_propagation(X, parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z4, Y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    print(\"Start train\")\n",
    "    model_path = 'E:/Projects/python/kaggle-test/model/titanic/simple.ckpt'\n",
    "    saver = tf.train.Saver()\n",
    "    if(restore_params):\n",
    "        with tf.Session() as sess:\n",
    "            # 读取之前训练好的数据\n",
    "            load_path = saver.restore(sess, model_path)\n",
    "            print(\"[+] Model restored from %s\" % load_path)\n",
    "            print('[+] Test accuracy is %f' % sess.run(accuracy, feed_dict={X: mnist.test.images, y_: mnist.test.labels}))\n",
    "        return\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = (X_train, y_train)\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "            #_ , epoch_cost = sess.run([optimizer, cost], feed_dict={X: X_train, Y: y_train})\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "        save_path = saver.save(sess, model_path)\n",
    "        print(\"[+] Model saved in file: %s\" % save_path)\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z4), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 712) (2, 712) (9, 179) (2, 179)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_pd_train.values\n",
    "X_test = X_pd_test.values\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "#print(y_train.shape)\n",
    "#print(X_test.shape)\n",
    "#print(y_test.shape)\n",
    "#print(X_train)\n",
    "#print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 712)\n",
      "Start train\n",
      "Cost after epoch 0: 2.833899\n",
      "Cost after epoch 100: 0.603623\n",
      "Cost after epoch 200: 0.495314\n",
      "Cost after epoch 300: 0.455634\n",
      "Cost after epoch 400: 0.447435\n",
      "Cost after epoch 500: 0.438751\n",
      "Cost after epoch 600: 0.431709\n",
      "Cost after epoch 700: 0.402088\n",
      "Cost after epoch 800: 0.409097\n",
      "Cost after epoch 900: 0.413475\n",
      "Cost after epoch 1000: 0.387385\n",
      "Cost after epoch 1100: 0.375397\n",
      "Cost after epoch 1200: 0.386034\n",
      "Cost after epoch 1300: nan\n",
      "Cost after epoch 1400: 0.353801\n",
      "Cost after epoch 1500: 0.350591\n",
      "Cost after epoch 1600: nan\n",
      "Cost after epoch 1700: 0.344955\n",
      "Cost after epoch 1800: 0.333529\n",
      "Cost after epoch 1900: 0.323603\n",
      "Cost after epoch 2000: 0.321417\n",
      "Cost after epoch 2100: 0.316709\n",
      "Cost after epoch 2200: 0.324969\n",
      "Cost after epoch 2300: 0.317653\n",
      "Cost after epoch 2400: 0.300880\n",
      "Cost after epoch 2500: 0.302950\n",
      "Cost after epoch 2600: 0.308651\n",
      "Cost after epoch 2700: 0.315822\n",
      "Cost after epoch 2800: 0.288611\n",
      "Cost after epoch 2900: 0.289902\n",
      "Cost after epoch 3000: 0.272074\n",
      "Cost after epoch 3100: 0.271732\n",
      "Cost after epoch 3200: 0.264321\n",
      "Cost after epoch 3300: 0.269651\n",
      "Cost after epoch 3400: nan\n",
      "Cost after epoch 3500: 0.255764\n",
      "Cost after epoch 3600: 0.262230\n",
      "Cost after epoch 3700: 0.252138\n",
      "Cost after epoch 3800: 0.243293\n",
      "Cost after epoch 3900: 0.239339\n",
      "Cost after epoch 4000: 0.240751\n",
      "Cost after epoch 4100: 0.231531\n",
      "Cost after epoch 4200: 0.233309\n",
      "Cost after epoch 4300: 0.236939\n",
      "Cost after epoch 4400: 0.223471\n",
      "Cost after epoch 4500: 0.230624\n",
      "Cost after epoch 4600: 0.222820\n",
      "Cost after epoch 4700: 0.235218\n",
      "Cost after epoch 4800: 0.213384\n",
      "Cost after epoch 4900: 0.210548\n",
      "Cost after epoch 5000: 0.213111\n",
      "Cost after epoch 5100: 0.208154\n",
      "Cost after epoch 5200: 0.212167\n",
      "Cost after epoch 5300: 0.211184\n",
      "Cost after epoch 5400: 0.207802\n",
      "Cost after epoch 5500: 0.214547\n",
      "Cost after epoch 5600: 0.205238\n",
      "Cost after epoch 5700: 0.211652\n",
      "Cost after epoch 5800: 0.199581\n",
      "Cost after epoch 5900: 0.198219\n",
      "Cost after epoch 6000: 0.190302\n",
      "Cost after epoch 6100: 0.180699\n",
      "Cost after epoch 6200: 0.210824\n",
      "Cost after epoch 6300: 0.180130\n",
      "Cost after epoch 6400: 0.175269\n",
      "Cost after epoch 6500: 0.248001\n",
      "Cost after epoch 6600: 0.171719\n",
      "Cost after epoch 6700: 0.169980\n",
      "Cost after epoch 6800: 0.173804\n",
      "Cost after epoch 6900: 0.164076\n",
      "Cost after epoch 7000: 0.180377\n",
      "Cost after epoch 7100: 0.185558\n",
      "Cost after epoch 7200: 0.160067\n",
      "Cost after epoch 7300: 0.145378\n",
      "Cost after epoch 7400: 0.163244\n",
      "Cost after epoch 7500: 0.136673\n",
      "Cost after epoch 7600: 0.151606\n",
      "Cost after epoch 7700: 0.153841\n",
      "Cost after epoch 7800: 0.148502\n",
      "Cost after epoch 7900: 0.144789\n",
      "Cost after epoch 8000: 0.141885\n",
      "Cost after epoch 8100: 0.140588\n",
      "Cost after epoch 8200: 0.132180\n",
      "Cost after epoch 8300: 0.128595\n",
      "Cost after epoch 8400: 0.129470\n",
      "Cost after epoch 8500: 0.131043\n",
      "Cost after epoch 8600: 0.139963\n",
      "Cost after epoch 8700: 0.125958\n",
      "Cost after epoch 8800: 0.140617\n",
      "Cost after epoch 8900: nan\n",
      "Cost after epoch 9000: 0.124521\n",
      "Cost after epoch 9100: 0.127759\n",
      "Cost after epoch 9200: nan\n",
      "Cost after epoch 9300: 0.175903\n",
      "Cost after epoch 9400: 0.151214\n",
      "Cost after epoch 9500: 0.149553\n",
      "Cost after epoch 9600: 0.158555\n",
      "Cost after epoch 9700: 0.162316\n",
      "Cost after epoch 9800: 0.141662\n",
      "Cost after epoch 9900: 0.125953\n",
      "Cost after epoch 10000: 0.141869\n",
      "Cost after epoch 10100: 0.140579\n",
      "Cost after epoch 10200: 0.115979\n",
      "Cost after epoch 10300: 0.150475\n",
      "Cost after epoch 10400: 0.123731\n",
      "Cost after epoch 10500: 0.116121\n",
      "Cost after epoch 10600: 0.111225\n",
      "Cost after epoch 10700: 0.109903\n",
      "Cost after epoch 10800: 0.116074\n",
      "Cost after epoch 10900: 0.126389\n",
      "Cost after epoch 11000: 0.116046\n",
      "Cost after epoch 11100: 0.102773\n",
      "Cost after epoch 11200: 0.104866\n",
      "Cost after epoch 11300: 0.121641\n",
      "Cost after epoch 11400: 0.112683\n",
      "Cost after epoch 11500: 0.109298\n",
      "Cost after epoch 11600: 0.098240\n",
      "Cost after epoch 11700: 0.100297\n",
      "Cost after epoch 11800: 0.097245\n",
      "Cost after epoch 11900: 0.111224\n",
      "Cost after epoch 12000: 0.111854\n",
      "Cost after epoch 12100: 0.091896\n",
      "Cost after epoch 12200: 0.098561\n",
      "Cost after epoch 12300: 0.093815\n",
      "Cost after epoch 12400: 0.111669\n",
      "Cost after epoch 12500: 0.097783\n",
      "Cost after epoch 12600: 0.097199\n",
      "Cost after epoch 12700: 0.086879\n",
      "Cost after epoch 12800: 0.091362\n",
      "Cost after epoch 12900: 0.081685\n",
      "Cost after epoch 13000: 0.100713\n",
      "Cost after epoch 13100: 0.082601\n",
      "Cost after epoch 13200: 0.078973\n",
      "Cost after epoch 13300: 0.079100\n",
      "Cost after epoch 13400: 0.072565\n",
      "Cost after epoch 13500: 0.078652\n",
      "Cost after epoch 13600: nan\n",
      "Cost after epoch 13700: 0.077712\n",
      "Cost after epoch 13800: 0.083959\n",
      "Cost after epoch 13900: 0.082111\n",
      "Cost after epoch 14000: 0.076939\n",
      "Cost after epoch 14100: 0.076035\n",
      "Cost after epoch 14200: 0.090921\n",
      "Cost after epoch 14300: 0.067015\n",
      "Cost after epoch 14400: 0.066732\n",
      "Cost after epoch 14500: 0.067607\n",
      "Cost after epoch 14600: nan\n",
      "Cost after epoch 14700: 0.094364\n",
      "Cost after epoch 14800: 0.072040\n",
      "Cost after epoch 14900: 0.073008\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fda74e2940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "[+] Model saved in file: E:/Projects/python/kaggle-test/model/titanic/simple.ckpt\n",
      "Train Accuracy: 0.973315\n",
      "Test Accuracy: 0.793296\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "parameters = model(X_train, y_train, X_test, y_test,num_epochs = 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 418)\n",
      "Start train\n",
      "INFO:tensorflow:Restoring parameters from E:/Projects/python/kaggle-test/model/titanic/simple.ckpt\n",
      "[+] Model restored from None\n",
      "[0 1 0 0 1 0 1 0 1 0 0 1 1 0 1 0 0 0 0 0 0 1 1 0 1 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "def predict(X_test):\n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_test.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = 2                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    #cost = compute_cost(Z3, Y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    #optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    print(\"Start train\")\n",
    "    model_path = 'E:/Projects/python/kaggle-test/model/titanic/simple.ckpt'\n",
    "    saver = tf.train.Saver()\n",
    "    accuracy = tf.argmax(Z3)\n",
    "    with tf.Session() as sess:\n",
    "    # 读取之前训练好的数据\n",
    "        load_path = saver.restore(sess, model_path)\n",
    "        print(\"[+] Model restored from %s\" % load_path)\n",
    "        #print('[+] Test accuracy is %f' % sess.run(accuracy, feed_dict={X: X_test}))\n",
    "        result = sess.run(accuracy, feed_dict={X: X_test})\n",
    "        print(result[:30])\n",
    "        return result\n",
    "print(X_test_all.shape)\n",
    "result = predict(X_test_all)\n",
    "#print(data_test[\"PassengerId\"][1])\n",
    "with open('E:/Projects/python/kaggle-test/result/titanic/titanic-result.csv','w') as file:\n",
    "    file.write(\"PassengerId,Survived\\n\")\n",
    "    for i in range(len(result)):\n",
    "        line = str(data_test[\"PassengerId\"][i]) + \",\" + str(result[i])\n",
    "        file.write(line)\n",
    "        file.write('\\n')\n",
    "        #spamwriter.writerow(['Spam', 'Lovely Spam', 'Wonderful Spam'])\n",
    "        #spamwriter.writerow([data_test[\"PassengerId\"][i], result[i]])\n",
    "        #print(data_test[\"PassengerId\"][i], result[i])\n",
    "\n",
    "#print(y_pd_train.T[:,:30][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "## START CODE HERE ## (PUT YOUR IMAGE NAME) \n",
    "my_image = \"thumbs_up.jpg\"\n",
    "## END CODE HERE ##\n",
    "\n",
    "# We preprocess your image to fit your algorithm.\n",
    "fname = \"images/\" + my_image\n",
    "image = np.array(ndimage.imread(fname, flatten=False))\n",
    "my_image = scipy.misc.imresize(image, size=(64,64)).reshape((1, 64*64*3)).T\n",
    "my_image_prediction = predict(my_image, parameters)\n",
    "\n",
    "plt.imshow(image)\n",
    "print(\"Your algorithm predicts: y = \" + str(np.squeeze(my_image_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"Placeholder:0\", shape=(9, ?), dtype=float32)\n",
      "Y = Tensor(\"Placeholder_1:0\", shape=(1, ?), dtype=float32)\n",
      "y = Tensor(\"add:0\", shape=(1, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
    "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "    \n",
    "    Tips:\n",
    "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "X = tf.placeholder(tf.float32, shape = (X_train.shape[0], None))\n",
    "Y = tf.placeholder(tf.float32, shape = (1, None))\n",
    "print(\"X = \" + str(X))\n",
    "print(\"Y = \" + str(Y))\n",
    "\n",
    "#b1 = tf.get_variable(\"b1\", [1], initializer = tf.zeros_initializer())\n",
    "#W1 = tf.get_variable(\"W1\", [791,1], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "'''\n",
    "shape of W1 is (output size, input feature size)\n",
    "'''\n",
    "b1 = tf.Variable(tf.zeros([1]))\n",
    "W1 = tf.Variable(tf.random_uniform([1,9]))\n",
    "y = tf.matmul(W1, X) + b1\n",
    "\n",
    "parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1}\n",
    "\n",
    "print(\"y = \" + str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(y - y_train))\n",
    "optimiser = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimiser.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 32256.4\n",
      "Cost: nan\n",
      "Cost: nan\n",
      "Cost: nan\n",
      "Cost: nan\n"
     ]
    }
   ],
   "source": [
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(0, 100):\n",
    "        _, batch_cost = sess.run([train, loss], feed_dict={X: X_train, Y: y_train})\n",
    "        if(step % 20 == 0):\n",
    "            print(\"Cost:\", batch_cost)\n",
    "            #print(step, sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-f0de8d79259e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-d1b2c73c62e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PassengerId'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'PassengerId'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m \u001b[1;34m'PassengerId'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Survived'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "ids = data_test['PassengerId']\n",
    "predictions = clf.predict(data_test.drop('PassengerId', axis=1))\n",
    "\n",
    "\n",
    "output = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\n",
    "# output.to_csv('titanic-predictions.csv', index = False)\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21468373cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pylab as P\n",
    "df = pd.read_csv('data/titanic/train.csv', header=0)\n",
    "df['Pclass'].hist()\n",
    "P.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 13)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'] = df['Sex'].map({'female':0, 'male':1}).astype(int)\n",
    "#df = df.dropna()\n",
    "train_data = df.values\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 12)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/titanic/train.csv', header=0)\n",
    "test_df = pd.read_csv('data/titanic/test.csv', header=0)\n",
    "full_df = train_df.append(test_df, ignore_index = True)\n",
    "print(full_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sex = pd.Series( np.where( full_df.Sex == 'male' , 1 , 0 ) , name = 'Sex' )\n",
    "#full_df.head()\n",
    "#embarked = pd.get_dummies(full_df.Embarked, prefix = 'Embarked')\n",
    "#embarked.head()\n",
    "#pClass = pd.get_dummies(full_df.Pclass, prefix = 'Pclass')\n",
    "#pClass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Student</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Braund,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4_quartile</td>\n",
       "      <td>C</td>\n",
       "      <td>Cumings,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Heikkinen,</td>\n",
       "      <td>Miss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4_quartile</td>\n",
       "      <td>C</td>\n",
       "      <td>Futrelle,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Allen,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Sex          Age  SibSp  Parch  \\\n",
       "0            1         0       3    male      Student      1      0   \n",
       "1            2         1       1  female        Adult      1      0   \n",
       "2            3         1       3  female  Young Adult      0      0   \n",
       "3            4         1       1  female  Young Adult      1      0   \n",
       "4            5         0       3    male  Young Adult      0      0   \n",
       "\n",
       "         Fare Cabin       Lname NamePrefix  \n",
       "0  1_quartile     N     Braund,        Mr.  \n",
       "1  4_quartile     C    Cumings,       Mrs.  \n",
       "2  1_quartile     N  Heikkinen,      Miss.  \n",
       "3  4_quartile     C   Futrelle,       Mrs.  \n",
       "4  2_quartile     N      Allen,        Mr.  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#below code copy from https://www.kaggle.com/jeffd23/scikit-learn-ml-from-start-to-finish\n",
    "#just to familier data transform\n",
    "def simplify_ages(df):\n",
    "    df.Age = df.Age.fillna(-0.5)\n",
    "    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n",
    "    group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n",
    "    categories = pd.cut(df.Age, bins, labels=group_names)\n",
    "    df.Age = categories\n",
    "    return df\n",
    "\n",
    "def simplify_cabins(df):\n",
    "    df.Cabin = df.Cabin.fillna('N')\n",
    "    df.Cabin = df.Cabin.apply(lambda x: x[0])\n",
    "    return df\n",
    "\n",
    "def simplify_fares(df):\n",
    "    df.Fare = df.Fare.fillna(-0.5)\n",
    "    bins = (-1, 0, 8, 15, 31, 1000)\n",
    "    group_names = ['Unknown', '1_quartile', '2_quartile', '3_quartile', '4_quartile']\n",
    "    categories = pd.cut(df.Fare, bins, labels=group_names)\n",
    "    df.Fare = categories\n",
    "    return df\n",
    "\n",
    "def format_name(df):\n",
    "    df['Lname'] = df.Name.apply(lambda x: x.split(' ')[0])\n",
    "    df['NamePrefix'] = df.Name.apply(lambda x: x.split(' ')[1])\n",
    "    return df    \n",
    "    \n",
    "def drop_features(df):\n",
    "    return df.drop(['Ticket', 'Name', 'Embarked'], axis=1)\n",
    "\n",
    "def transform_features(df):\n",
    "    df = simplify_ages(df)\n",
    "    df = simplify_cabins(df)\n",
    "    df = simplify_fares(df)\n",
    "    df = format_name(df)\n",
    "    df = drop_features(df)\n",
    "    return df\n",
    "\n",
    "data_train = transform_features(train_df)\n",
    "data_test = transform_features(test_df)\n",
    "data_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>329</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>267</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex  Age  SibSp  Parch  Fare  Cabin  Lname  \\\n",
       "0            1         0       3    1    4      1      0     0      7    100   \n",
       "1            2         1       1    0    0      1      0     3      2    182   \n",
       "2            3         1       3    0    7      0      0     0      7    329   \n",
       "3            4         1       1    0    7      1      0     3      2    267   \n",
       "4            5         0       3    1    7      0      0     1      7     15   \n",
       "\n",
       "   NamePrefix  \n",
       "0          19  \n",
       "1          20  \n",
       "2          16  \n",
       "3          20  \n",
       "4          19  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "def encode_features(df_train, df_test):\n",
    "    features = ['Fare', 'Cabin', 'Age', 'Sex', 'Lname', 'NamePrefix']\n",
    "    df_combined = pd.concat([df_train[features], df_test[features]])\n",
    "    \n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(df_combined[feature])\n",
    "        df_train[feature] = le.transform(df_train[feature])\n",
    "        df_test[feature] = le.transform(df_test[feature])\n",
    "    return df_train, df_test\n",
    "    \n",
    "data_train, data_test = encode_features(data_train, data_test)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train:(712, 9)\n",
      "Y Train:(712,)\n",
      "X_train :  (9, 712)\n",
      "Y train :  (712, 1)\n",
      "X_test :  (9, 179)\n",
      "Y test :  (179, 1)\n",
      "y_train:  (2, 712)\n",
      "y_test:  (2, 179)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_all = data_train.drop(['Survived', 'PassengerId'], axis=1)\n",
    "y_all = data_train['Survived']\n",
    "\n",
    "num_test = 0.20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=num_test, random_state=23)\n",
    "print(\"X Train:\" + str(X_train.shape))\n",
    "print(\"Y Train:\" + str(y_train.shape))\n",
    "\n",
    "X_pd_train = X_train.T\n",
    "y_pd_train = y_train.values.reshape(y_train.shape[0], 1)\n",
    "#y_train = y_train.T\n",
    "\n",
    "X_pd_test = X_test.T\n",
    "y_pd_test = y_test.values.reshape(y_test.shape[0], 1)\n",
    "#y_test = y_test.T\n",
    "print(\"X_train : \", X_pd_train.shape)\n",
    "print(\"Y train : \", y_pd_train.shape)\n",
    "print(\"X_test : \", X_pd_test.shape)\n",
    "print(\"Y test : \", y_pd_test.shape)\n",
    "\n",
    "#yy = tf.one_hot(y_train, depth=2)\n",
    "y_train1 = np.eye(2)[y_train.values.reshape(y_train.shape[0])]\n",
    "\n",
    "y_train = y_train1.T\n",
    "\n",
    "y_test1 = np.eye(2)[y_test.values.reshape(y_test.shape[0])]\n",
    "\n",
    "y_test = y_test1.T\n",
    "\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"y_test: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
    "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "    \n",
    "    Tips:\n",
    "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    X = tf.placeholder(tf.float32, shape = (n_x, None))\n",
    "    Y = tf.placeholder(tf.float32, shape = (n_y, None))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [25, 9]\n",
    "                        b1 : [25, 1]\n",
    "                        W2 : [12, 25]\n",
    "                        b2 : [12, 1]\n",
    "                        W3 : [1, 12]\n",
    "                        b3 : [1, 1]\n",
    "    W.shape(n(l), n_x)\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "    \n",
    "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
    "        \n",
    "    ### START CODE HERE ### (approx. 6 lines of code)\n",
    "    W1 = tf.get_variable(\"W1\", [125,9], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [125,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [120, 125], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [120, 1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [2, 120], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [2, 1], initializer = tf.zeros_initializer())\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve the parameters from the dictionary \"parameters\" \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    \n",
    "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                                              # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                              # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                                              # Z2 = np.dot(W2, a1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                              # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)                                              # Z3 = np.dot(W3,Z2) + b3\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "    \n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "    \n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "    \n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    \n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def random_mini_batches(X_train, Y_train, minibatch_size, seed):\n",
    "    minibatches = []\n",
    "    length = X_train.shape[1]\n",
    "    batch_count = length / minibatch_size\n",
    "    #print(batch_count)\n",
    "    startRandom = random.randint(0, length)\n",
    "    for i in range(int(batch_count)):\n",
    "        start = startRandom + i * minibatch_size\n",
    "        end = start + minibatch_size\n",
    "        if(start >= length):\n",
    "            start -= length\n",
    "        if(end >= length):\n",
    "            end -= length\n",
    "        if(start > end):\n",
    "            #end -= length\n",
    "            continue\n",
    "        \n",
    "        minibatch = (X_train[:,start:end], y_train[:,start:end])\n",
    "       # print(minibatch[0].shape, start, end)\n",
    "        minibatches.append(minibatch)\n",
    "    return minibatches\n",
    "minibatches = random_mini_batches(X_train, y_train, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
    "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
    "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
    "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "    \n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    print(\"Start train\")\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = (X_train, y_train)\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                ### END CODE HERE ###\n",
    "                \n",
    "                epoch_cost += minibatch_cost / num_minibatches\n",
    "            #_ , epoch_cost = sess.run([optimizer, cost], feed_dict={X: X_train, Y: y_train})\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "                \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "        \n",
    "        return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 712)\n",
      "(2, 712)\n",
      "(9, 179)\n",
      "(2, 179)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_pd_train.values\n",
    "X_test = X_pd_test.values\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "#print(X_train)\n",
    "#print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 712)\n",
      "Start train\n",
      "Cost after epoch 0: 0.696486\n",
      "Cost after epoch 100: 0.525219\n",
      "Cost after epoch 200: 0.463159\n",
      "Cost after epoch 300: 0.448226\n",
      "Cost after epoch 400: 0.449774\n",
      "Cost after epoch 500: 0.433938\n",
      "Cost after epoch 600: 0.415599\n",
      "Cost after epoch 700: 0.395751\n",
      "Cost after epoch 800: 0.413207\n",
      "Cost after epoch 900: 0.395197\n",
      "Cost after epoch 1000: 0.386213\n",
      "Cost after epoch 1100: 0.389396\n",
      "Cost after epoch 1200: 0.415742\n",
      "Cost after epoch 1300: 0.367261\n",
      "Cost after epoch 1400: 0.370242\n",
      "Cost after epoch 1500: 0.374101\n",
      "Cost after epoch 1600: 0.361927\n",
      "Cost after epoch 1700: 0.354578\n",
      "Cost after epoch 1800: 0.341429\n",
      "Cost after epoch 1900: 0.343343\n",
      "Cost after epoch 2000: 0.362448\n",
      "Cost after epoch 2100: 0.339581\n",
      "Cost after epoch 2200: 0.338386\n",
      "Cost after epoch 2300: 0.351030\n",
      "Cost after epoch 2400: 0.332977\n",
      "Cost after epoch 2500: 0.331446\n",
      "Cost after epoch 2600: 0.318061\n",
      "Cost after epoch 2700: 0.313574\n",
      "Cost after epoch 2800: 0.378303\n",
      "Cost after epoch 2900: 0.378240\n",
      "Cost after epoch 3000: 0.309350\n",
      "Cost after epoch 3100: 0.330342\n",
      "Cost after epoch 3200: 0.297555\n",
      "Cost after epoch 3300: 0.322108\n",
      "Cost after epoch 3400: 0.307859\n",
      "Cost after epoch 3500: 0.317525\n",
      "Cost after epoch 3600: 0.310070\n",
      "Cost after epoch 3700: 0.291572\n",
      "Cost after epoch 3800: 0.287072\n",
      "Cost after epoch 3900: 0.283309\n",
      "Cost after epoch 4000: 0.284701\n",
      "Cost after epoch 4100: 0.283553\n",
      "Cost after epoch 4200: 0.261119\n",
      "Cost after epoch 4300: 0.280716\n",
      "Cost after epoch 4400: 0.263767\n",
      "Cost after epoch 4500: 0.275280\n",
      "Cost after epoch 4600: 0.274789\n",
      "Cost after epoch 4700: 0.263789\n",
      "Cost after epoch 4800: 0.271471\n",
      "Cost after epoch 4900: 0.260637\n",
      "Cost after epoch 5000: 0.254222\n",
      "Cost after epoch 5100: 0.256869\n",
      "Cost after epoch 5200: 0.275780\n",
      "Cost after epoch 5300: 0.251543\n",
      "Cost after epoch 5400: 0.264509\n",
      "Cost after epoch 5500: 0.251114\n",
      "Cost after epoch 5600: 0.247803\n",
      "Cost after epoch 5700: 0.258474\n",
      "Cost after epoch 5800: 0.267927\n",
      "Cost after epoch 5900: 0.251097\n",
      "Cost after epoch 6000: 0.233485\n",
      "Cost after epoch 6100: 0.233326\n",
      "Cost after epoch 6200: 0.235441\n",
      "Cost after epoch 6300: 0.244109\n",
      "Cost after epoch 6400: 0.238381\n",
      "Cost after epoch 6500: 0.228971\n",
      "Cost after epoch 6600: 0.224554\n",
      "Cost after epoch 6700: 0.226816\n",
      "Cost after epoch 6800: 0.235684\n",
      "Cost after epoch 6900: 0.228311\n",
      "Cost after epoch 7000: 0.223853\n",
      "Cost after epoch 7100: 0.220572\n",
      "Cost after epoch 7200: 0.223842\n",
      "Cost after epoch 7300: 0.221663\n",
      "Cost after epoch 7400: 0.228172\n",
      "Cost after epoch 7500: 0.214193\n",
      "Cost after epoch 7600: 0.220110\n",
      "Cost after epoch 7700: 0.211675\n",
      "Cost after epoch 7800: 0.209772\n",
      "Cost after epoch 7900: 0.210689\n",
      "Cost after epoch 8000: 0.207030\n",
      "Cost after epoch 8100: 0.213170\n",
      "Cost after epoch 8200: 0.215335\n",
      "Cost after epoch 8300: 0.208553\n",
      "Cost after epoch 8400: 0.198186\n",
      "Cost after epoch 8500: 0.197892\n",
      "Cost after epoch 8600: 0.206183\n",
      "Cost after epoch 8700: 0.198213\n",
      "Cost after epoch 8800: 0.209114\n",
      "Cost after epoch 8900: 0.199222\n",
      "Cost after epoch 9000: 0.221894\n",
      "Cost after epoch 9100: 0.198971\n",
      "Cost after epoch 9200: 0.188218\n",
      "Cost after epoch 9300: 0.192245\n",
      "Cost after epoch 9400: 0.195759\n",
      "Cost after epoch 9500: 0.193317\n",
      "Cost after epoch 9600: 0.208043\n",
      "Cost after epoch 9700: 0.195294\n",
      "Cost after epoch 9800: 0.183400\n",
      "Cost after epoch 9900: 0.193528\n",
      "Cost after epoch 10000: 0.185753\n",
      "Cost after epoch 10100: 0.189418\n",
      "Cost after epoch 10200: 0.183996\n",
      "Cost after epoch 10300: 0.173576\n",
      "Cost after epoch 10400: 0.174113\n",
      "Cost after epoch 10500: 0.170463\n",
      "Cost after epoch 10600: 0.181851\n",
      "Cost after epoch 10700: 0.186729\n",
      "Cost after epoch 10800: 0.213815\n",
      "Cost after epoch 10900: 0.168703\n",
      "Cost after epoch 11000: 0.172361\n",
      "Cost after epoch 11100: 0.163460\n",
      "Cost after epoch 11200: 0.163872\n",
      "Cost after epoch 11300: 0.160986\n",
      "Cost after epoch 11400: 0.170451\n",
      "Cost after epoch 11500: 0.167642\n",
      "Cost after epoch 11600: 0.165182\n",
      "Cost after epoch 11700: 0.168194\n",
      "Cost after epoch 11800: 0.159319\n",
      "Cost after epoch 11900: 0.164719\n",
      "Cost after epoch 12000: 0.154549\n",
      "Cost after epoch 12100: 0.170021\n",
      "Cost after epoch 12200: 0.154396\n",
      "Cost after epoch 12300: 0.152434\n",
      "Cost after epoch 12400: 0.197743\n",
      "Cost after epoch 12500: 0.165711\n",
      "Cost after epoch 12600: 0.161426\n",
      "Cost after epoch 12700: 0.158333\n",
      "Cost after epoch 12800: 0.165140\n",
      "Cost after epoch 12900: 0.151638\n",
      "Cost after epoch 13000: 0.164741\n",
      "Cost after epoch 13100: 0.164343\n",
      "Cost after epoch 13200: 0.156079\n",
      "Cost after epoch 13300: 0.152129\n",
      "Cost after epoch 13400: 0.145958\n",
      "Cost after epoch 13500: 0.166604\n",
      "Cost after epoch 13600: 0.171065\n",
      "Cost after epoch 13700: 0.146101\n",
      "Cost after epoch 13800: 0.170200\n",
      "Cost after epoch 13900: 0.146527\n",
      "Cost after epoch 14000: 0.174726\n",
      "Cost after epoch 14100: 0.145299\n",
      "Cost after epoch 14200: 0.165357\n",
      "Cost after epoch 14300: 0.158909\n",
      "Cost after epoch 14400: 0.147561\n",
      "Cost after epoch 14500: 0.142194\n",
      "Cost after epoch 14600: 0.139226\n",
      "Cost after epoch 14700: 0.142419\n",
      "Cost after epoch 14800: 0.138494\n",
      "Cost after epoch 14900: 0.154792\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1K7qG5bZtgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21468a35e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 0.949438\n",
      "Test Accuracy: 0.804469\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "parameters = model(X_train, y_train, X_test, y_test,num_epochs = 15000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "\n",
    "## START CODE HERE ## (PUT YOUR IMAGE NAME) \n",
    "my_image = \"thumbs_up.jpg\"\n",
    "## END CODE HERE ##\n",
    "\n",
    "# We preprocess your image to fit your algorithm.\n",
    "fname = \"images/\" + my_image\n",
    "image = np.array(ndimage.imread(fname, flatten=False))\n",
    "my_image = scipy.misc.imresize(image, size=(64,64)).reshape((1, 64*64*3)).T\n",
    "my_image_prediction = predict(my_image, parameters)\n",
    "\n",
    "plt.imshow(image)\n",
    "print(\"Your algorithm predicts: y = \" + str(np.squeeze(my_image_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"Placeholder:0\", shape=(9, ?), dtype=float32)\n",
      "Y = Tensor(\"Placeholder_1:0\", shape=(1, ?), dtype=float32)\n",
      "y = Tensor(\"add:0\", shape=(1, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
    "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "    \n",
    "    Tips:\n",
    "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "X = tf.placeholder(tf.float32, shape = (X_train.shape[0], None))\n",
    "Y = tf.placeholder(tf.float32, shape = (1, None))\n",
    "print(\"X = \" + str(X))\n",
    "print(\"Y = \" + str(Y))\n",
    "\n",
    "#b1 = tf.get_variable(\"b1\", [1], initializer = tf.zeros_initializer())\n",
    "#W1 = tf.get_variable(\"W1\", [791,1], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "'''\n",
    "shape of W1 is (output size, input feature size)\n",
    "'''\n",
    "b1 = tf.Variable(tf.zeros([1]))\n",
    "W1 = tf.Variable(tf.random_uniform([1,9]))\n",
    "y = tf.matmul(W1, X) + b1\n",
    "\n",
    "parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1}\n",
    "\n",
    "print(\"y = \" + str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(y - y_train))\n",
    "optimiser = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimiser.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 32256.4\n",
      "Cost: nan\n",
      "Cost: nan\n",
      "Cost: nan\n",
      "Cost: nan\n"
     ]
    }
   ],
   "source": [
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(0, 100):\n",
    "        _, batch_cost = sess.run([train, loss], feed_dict={X: X_train, Y: y_train})\n",
    "        if(step % 20 == 0):\n",
    "            print(\"Cost:\", batch_cost)\n",
    "            #print(step, sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-f0de8d79259e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-d1b2c73c62e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'PassengerId'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'PassengerId'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m \u001b[1;34m'PassengerId'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Survived'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "ids = data_test['PassengerId']\n",
    "predictions = clf.predict(data_test.drop('PassengerId', axis=1))\n",
    "\n",
    "\n",
    "output = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\n",
    "# output.to_csv('titanic-predictions.csv', index = False)\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

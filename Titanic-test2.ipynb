{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n",
      "(891, 12)\n",
      "[['1' '0' '3' ..., '7.25' '' 'S']\n",
      " ['2' '1' '1' ..., '71.2833' 'C85' 'C']\n",
      " ['3' '1' '3' ..., '7.925' '' 'S']\n",
      " ..., \n",
      " ['889' '0' '3' ..., '23.45' '' 'S']\n",
      " ['890' '1' '1' ..., '30' 'C148' 'C']\n",
      " ['891' '0' '3' ..., '7.75' '' 'Q']]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import csv as csv\n",
    "\n",
    "csv_file = csv.reader(open('data/titanic/train.csv', 'rt'))\n",
    "\n",
    "header = next(csv_file) #only in python 3\n",
    "data = []\n",
    "\n",
    "for row in csv_file:\n",
    "    data.append(row)\n",
    "\n",
    "data = np.array(data)\n",
    "print(header)\n",
    "print(data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJDXOopekxv0fmxt8+3YfryMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ab1c72ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pylab as P\n",
    "df = pd.read_csv('data/titanic/train.csv', header=0)\n",
    "df['Pclass'].hist()\n",
    "P.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Gender'] = df['Sex'].map({'female':0, 'male':1}).astype(int)\n",
    "#df = df.dropna()\n",
    "train_data = df.values\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1309, 12)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('data/titanic/train.csv', header=0)\n",
    "test_df = pd.read_csv('data/titanic/test.csv', header=0)\n",
    "full_df = train_df.append(test_df, ignore_index = True)\n",
    "print(full_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sex = pd.Series( np.where( full_df.Sex == 'male' , 1 , 0 ) , name = 'Sex' )\n",
    "#full_df.head()\n",
    "#embarked = pd.get_dummies(full_df.Embarked, prefix = 'Embarked')\n",
    "#embarked.head()\n",
    "#pClass = pd.get_dummies(full_df.Pclass, prefix = 'Pclass')\n",
    "#pClass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Student</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Braund,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4_quartile</td>\n",
       "      <td>C</td>\n",
       "      <td>Cumings,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Heikkinen,</td>\n",
       "      <td>Miss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4_quartile</td>\n",
       "      <td>C</td>\n",
       "      <td>Futrelle,</td>\n",
       "      <td>Mrs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>Young Adult</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2_quartile</td>\n",
       "      <td>N</td>\n",
       "      <td>Allen,</td>\n",
       "      <td>Mr.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass     Sex          Age  SibSp  Parch  \\\n",
       "0            1         0       3    male      Student      1      0   \n",
       "1            2         1       1  female        Adult      1      0   \n",
       "2            3         1       3  female  Young Adult      0      0   \n",
       "3            4         1       1  female  Young Adult      1      0   \n",
       "4            5         0       3    male  Young Adult      0      0   \n",
       "\n",
       "         Fare Cabin       Lname NamePrefix  \n",
       "0  1_quartile     N     Braund,        Mr.  \n",
       "1  4_quartile     C    Cumings,       Mrs.  \n",
       "2  1_quartile     N  Heikkinen,      Miss.  \n",
       "3  4_quartile     C   Futrelle,       Mrs.  \n",
       "4  2_quartile     N      Allen,        Mr.  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#below code copy from https://www.kaggle.com/jeffd23/scikit-learn-ml-from-start-to-finish\n",
    "#just to familier data transform\n",
    "def simplify_ages(df):\n",
    "    df.Age = df.Age.fillna(-0.5)\n",
    "    bins = (-1, 0, 5, 12, 18, 25, 35, 60, 120)\n",
    "    group_names = ['Unknown', 'Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\n",
    "    categories = pd.cut(df.Age, bins, labels=group_names)\n",
    "    df.Age = categories\n",
    "    return df\n",
    "\n",
    "def simplify_cabins(df):\n",
    "    df.Cabin = df.Cabin.fillna('N')\n",
    "    df.Cabin = df.Cabin.apply(lambda x: x[0])\n",
    "    return df\n",
    "\n",
    "def simplify_fares(df):\n",
    "    df.Fare = df.Fare.fillna(-0.5)\n",
    "    bins = (-1, 0, 8, 15, 31, 1000)\n",
    "    group_names = ['Unknown', '1_quartile', '2_quartile', '3_quartile', '4_quartile']\n",
    "    categories = pd.cut(df.Fare, bins, labels=group_names)\n",
    "    df.Fare = categories\n",
    "    return df\n",
    "\n",
    "def format_name(df):\n",
    "    df['Lname'] = df.Name.apply(lambda x: x.split(' ')[0])\n",
    "    df['NamePrefix'] = df.Name.apply(lambda x: x.split(' ')[1])\n",
    "    return df    \n",
    "    \n",
    "def drop_features(df):\n",
    "    return df.drop(['Ticket', 'Name', 'Embarked'], axis=1)\n",
    "\n",
    "def transform_features(df):\n",
    "    df = simplify_ages(df)\n",
    "    df = simplify_cabins(df)\n",
    "    df = simplify_fares(df)\n",
    "    df = format_name(df)\n",
    "    df = drop_features(df)\n",
    "    return df\n",
    "\n",
    "data_train = transform_features(train_df)\n",
    "data_test = transform_features(test_df)\n",
    "data_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Lname</th>\n",
       "      <th>NamePrefix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>329</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>267</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Sex  Age  SibSp  Parch  Fare  Cabin  Lname  \\\n",
       "0            1         0       3    1    4      1      0     0      7    100   \n",
       "1            2         1       1    0    0      1      0     3      2    182   \n",
       "2            3         1       3    0    7      0      0     0      7    329   \n",
       "3            4         1       1    0    7      1      0     3      2    267   \n",
       "4            5         0       3    1    7      0      0     1      7     15   \n",
       "\n",
       "   NamePrefix  \n",
       "0          19  \n",
       "1          20  \n",
       "2          16  \n",
       "3          20  \n",
       "4          19  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "def encode_features(df_train, df_test):\n",
    "    features = ['Fare', 'Cabin', 'Age', 'Sex', 'Lname', 'NamePrefix']\n",
    "    df_combined = pd.concat([df_train[features], df_test[features]])\n",
    "    \n",
    "    for feature in features:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le = le.fit(df_combined[feature])\n",
    "        df_train[feature] = le.transform(df_train[feature])\n",
    "        df_test[feature] = le.transform(df_test[feature])\n",
    "    return df_train, df_test\n",
    "    \n",
    "data_train, data_test = encode_features(data_train, data_test)\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train:(712, 9)\n",
      "Y Train:(712,)\n",
      "X_train :  (9, 712)\n",
      "Y train :  (1, 712)\n",
      "X_test :  (9, 179)\n",
      "Y test :  (1, 179)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_all = data_train.drop(['Survived', 'PassengerId'], axis=1)\n",
    "y_all = data_train['Survived']\n",
    "\n",
    "num_test = 0.20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=num_test, random_state=23)\n",
    "print(\"X Train:\" + str(X_train.shape))\n",
    "print(\"Y Train:\" + str(y_train.shape))\n",
    "\n",
    "X_train = X_train.T\n",
    "y_train = y_train.values.reshape(y_train.shape[0], 1)\n",
    "y_train = y_train.T\n",
    "\n",
    "X_test = X_test.T\n",
    "y_test = y_test.values.reshape(y_test.shape[0], 1)\n",
    "y_test = y_test.T\n",
    "print(\"X_train : \", X_train.shape)\n",
    "print(\"Y train : \", y_train.shape)\n",
    "print(\"X_test : \", X_test.shape)\n",
    "print(\"Y test : \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"Placeholder_40:0\", shape=(9, ?), dtype=float32)\n",
      "Y = Tensor(\"Placeholder_41:0\", shape=(1, ?), dtype=float32)\n",
      "y = Tensor(\"add_4:0\", shape=(1, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
    "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
    "    \n",
    "    Tips:\n",
    "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "X = tf.placeholder(tf.float32, shape = (X_train.shape[0], None))\n",
    "Y = tf.placeholder(tf.float32, shape = (1, None))\n",
    "print(\"X = \" + str(X))\n",
    "print(\"Y = \" + str(Y))\n",
    "\n",
    "#b1 = tf.get_variable(\"b1\", [1], initializer = tf.zeros_initializer())\n",
    "#W1 = tf.get_variable(\"W1\", [791,1], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "'''\n",
    "shape of W1 is (output size, input feature size)\n",
    "'''\n",
    "b1 = tf.Variable(tf.zeros([1]))\n",
    "W1 = tf.Variable(tf.random_uniform([1,9]))\n",
    "y = tf.matmul(W1, X) + b1\n",
    "\n",
    "parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1}\n",
    "\n",
    "print(\"y = \" + str(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(y - y_train))\n",
    "optimiser = tf.train.GradientDescentOptimizer(0.5)\n",
    "train = optimiser.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: 93843.0\n",
      "Cost: nan\n",
      "Cost: nan\n",
      "Cost: nan\n",
      "Cost: nan\n"
     ]
    }
   ],
   "source": [
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(0, 100):\n",
    "        _, batch_cost = sess.run([train, loss], feed_dict={X: X_train, Y: y_train})\n",
    "        if(step % 20 == 0):\n",
    "            print(\"Cost:\", batch_cost)\n",
    "            #print(step, sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TEST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.ensemble import RandomForestClassifier\\nfrom sklearn.metrics import make_scorer, accuracy_score\\nfrom sklearn.model_selection import GridSearchCV\\n\\n# Choose the type of classifier. \\nclf = RandomForestClassifier()\\n\\n# Choose some parameter combinations to try\\nparameters = {'n_estimators': [4, 6, 9], \\n              'max_features': ['log2', 'sqrt','auto'], \\n              'criterion': ['entropy', 'gini'],\\n              'max_depth': [2, 3, 5, 10], \\n              'min_samples_split': [2, 3, 5],\\n              'min_samples_leaf': [1,5,8]\\n             }\\n\\n# Type of scoring used to compare parameter combinations\\nacc_scorer = make_scorer(accuracy_score)\\n\\n# Run the grid search\\ngrid_obj = GridSearchCV(clf, parameters, scoring=acc_scorer)\\ngrid_obj = grid_obj.fit(X_train, y_train)\\n\\n# Set the clf to the best combination of parameters\\nclf = grid_obj.best_estimator_\\n\\n# Fit the best algorithm to the data. \\nclf.fit(X_train, y_train)\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Choose the type of classifier. \n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "parameters = {'n_estimators': [4, 6, 9], \n",
    "              'max_features': ['log2', 'sqrt','auto'], \n",
    "              'criterion': ['entropy', 'gini'],\n",
    "              'max_depth': [2, 3, 5, 10], \n",
    "              'min_samples_split': [2, 3, 5],\n",
    "              'min_samples_leaf': [1,5,8]\n",
    "             }\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=acc_scorer)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data. \n",
    "clf.fit(X_train, y_train)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.810055865922\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 accuracy: 0.8\n",
      "Fold 2 accuracy: 0.8539325842696629\n",
      "Fold 3 accuracy: 0.797752808988764\n",
      "Fold 4 accuracy: 0.8651685393258427\n",
      "Fold 5 accuracy: 0.8314606741573034\n",
      "Fold 6 accuracy: 0.8089887640449438\n",
      "Fold 7 accuracy: 0.7752808988764045\n",
      "Fold 8 accuracy: 0.8089887640449438\n",
      "Fold 9 accuracy: 0.8651685393258427\n",
      "Fold 10 accuracy: 0.8314606741573034\n",
      "Mean Accuracy: 0.8238202247191012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dada\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "def run_kfold(clf):\n",
    "    kf = KFold(891, n_folds=10)\n",
    "    outcomes = []\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf:\n",
    "        fold += 1\n",
    "        X_train, X_test = X_all.values[train_index], X_all.values[test_index]\n",
    "        y_train, y_test = y_all.values[train_index], y_all.values[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        outcomes.append(accuracy)\n",
    "        print(\"Fold {0} accuracy: {1}\".format(fold, accuracy))     \n",
    "    mean_outcome = np.mean(outcomes)\n",
    "    print(\"Mean Accuracy: {0}\".format(mean_outcome)) \n",
    "\n",
    "run_kfold(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         0\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = data_test['PassengerId']\n",
    "predictions = clf.predict(data_test.drop('PassengerId', axis=1))\n",
    "\n",
    "\n",
    "output = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\n",
    "# output.to_csv('titanic-predictions.csv', index = False)\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
